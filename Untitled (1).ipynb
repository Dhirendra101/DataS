{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c8e754-f66a-4a30-adf2-412116bc033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk) (2022.8.17)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d7be31-e90b-4457-8c95-8d220f27b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae9bd2b-e850-47ac-9a35-8f62f59059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "vocab_size = 5000\n",
    "\n",
    "# Dimension of the dense embedding.\n",
    "embedding_dim = 128\n",
    "\n",
    "# Max number of words in each complaint.\n",
    "max_length = 100\n",
    "\n",
    "# Truncate and padding options\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b389343a-5f30-461e-a744-d10ca5b98367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('BBC News Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb19d5cb-c9f0-4e95-b33d-c0286a88cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6219b9d-52ad-4015-bab9-d2d3c2bafe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do some text cleanup\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "REMOVE_NUM = re.compile('[\\d+]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text: a string\n",
    "    return: modified initial string\n",
    "    \"\"\"\n",
    "    # lowercase text\n",
    "    text = text.lower() \n",
    "\n",
    "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
    "    \n",
    "    # Remove the XXXX values\n",
    "    text = text.replace('x', '') \n",
    "    \n",
    "    # Remove white space\n",
    "    text = REMOVE_NUM.sub('', text)\n",
    "\n",
    "    #  delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) \n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    \n",
    "    # removes any words composed of less than 2 or more than 21 letters\n",
    "    text = ' '.join(word for word in text.split() if (len(word) >= 2 and len(word) <= 21))\n",
    "\n",
    "    # Stemming the words\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5101ec17-9e74-497e-a024-711899cc0b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       worldcom eboss launch defenc lawyer defend for...\n",
       "1       german busi confid slide german busi confid fe...\n",
       "2       bbc poll indic econom gloom citizen major nati...\n",
       "3       lifestyl govern mobil choic faster better funk...\n",
       "4       enron boss payout eighteen former enron direct...\n",
       "                              ...                        \n",
       "1485    doubl evict big brother model capric holbi cit...\n",
       "1486    dj doubl act revamp chart show dj duo jk joel ...\n",
       "1487    weak dollar hit reuter revenu media group reut...\n",
       "1488    appl ipod famili epand market appl epand ipod ...\n",
       "1489    santi worm make unwelcom visit thousand websit...\n",
       "Name: Text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Text\"] = dataset[\"Text\"].apply(clean_text)\n",
    "dataset[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b72bce-881f-46fe-8437-4740205398f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffel the dataset to make sure we get an equal distribution of the data before splitting into train and test sets\n",
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d891241-b548-474c-9646-7cbc711880d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192,) (1192, 1)\n"
     ]
    }
   ],
   "source": [
    "News = dataset[\"Text\"].values\n",
    "labels = dataset[[\"Category\"]].values\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(News,labels, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09003d0a-8855-4c46-bb5e-2c00961c2e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tech'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886dc86a-a63b-458b-a7c8-767b3b7c5d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15914 unique tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'said': 2,\n",
       " 'mr': 3,\n",
       " 'year': 4,\n",
       " 'would': 5,\n",
       " 'also': 6,\n",
       " 'peopl': 7,\n",
       " 'new': 8,\n",
       " 'us': 9,\n",
       " 'one': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "dict(list(word_index.items())[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d02917a-a0c1-4984-85c1-9eeaafde50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1192, 100)\n",
      "Shape of data tensor: (298, 100)\n"
     ]
    }
   ],
   "source": [
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "validation_seq = tokenizer.texts_to_sequences(X_test)\n",
    "validation_padded = pad_sequences(validation_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print('Shape of data tensor:', train_padded.shape)\n",
    "print('Shape of data tensor:', validation_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff0472e-228c-451a-afad-96b7619cf776",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = OneHotEncoder()\n",
    "\n",
    "training_labels = encode.fit_transform(y_train)\n",
    "validation_labels = encode.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "577e1efc-dd69-41b6-80ef-fc936eae2f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d54cb6-7fb0-48be-8bba-989c4d18a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "training_labels = training_labels.toarray()\n",
    "validation_labels = validation_labels.toarray()\n",
    "\n",
    "print(type(training_labels))\n",
    "print(type(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90bafc25-2167-4a8a-8be0-36f98cb37380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300f4ffe-5f51-4de3-8c25-b01dbd8b6fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 13:20:29.488288: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 2s 38ms/step - loss: 1.6168 - accuracy: 0.2151 - val_loss: 1.5640 - val_accuracy: 0.3766 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.5224 - accuracy: 0.3295 - val_loss: 1.5045 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 1.4302 - accuracy: 0.4365 - val_loss: 1.4052 - val_accuracy: 0.6611 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 1.2903 - accuracy: 0.5645 - val_loss: 1.2576 - val_accuracy: 0.7657 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 1.1188 - accuracy: 0.6705 - val_loss: 1.0708 - val_accuracy: 0.8368 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.9684 - accuracy: 0.7114 - val_loss: 0.8930 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.8055 - accuracy: 0.7849 - val_loss: 0.7364 - val_accuracy: 0.8828 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.7012 - accuracy: 0.8006 - val_loss: 0.6229 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.5838 - accuracy: 0.8468 - val_loss: 0.5485 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.5085 - accuracy: 0.8646 - val_loss: 0.4896 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.4659 - accuracy: 0.8678 - val_loss: 0.4389 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.3770 - accuracy: 0.9024 - val_loss: 0.3939 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.3585 - accuracy: 0.9192 - val_loss: 0.3523 - val_accuracy: 0.9121 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.3116 - accuracy: 0.9150 - val_loss: 0.3292 - val_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.3089 - accuracy: 0.9108 - val_loss: 0.3155 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.2413 - accuracy: 0.9496 - val_loss: 0.3015 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.2409 - accuracy: 0.9391 - val_loss: 0.2843 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.2193 - accuracy: 0.9381 - val_loss: 0.2746 - val_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.1899 - accuracy: 0.9517 - val_loss: 0.2639 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1841 - accuracy: 0.9528 - val_loss: 0.2562 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1638 - accuracy: 0.9549 - val_loss: 0.2479 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1863 - accuracy: 0.9538 - val_loss: 0.2416 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1629 - accuracy: 0.9507 - val_loss: 0.2337 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=train_padded.shape[1]))\n",
    "\n",
    "model.add(Conv1D(48, 5, activation='relu', padding='valid'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(train_padded, training_labels, shuffle=True ,\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001), \n",
    "                               EarlyStopping(monitor='val_loss', mode='min', patience=2, verbose=1),\n",
    "                               EarlyStopping(monitor='val_accuracy', mode='max', patience=5, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25821242-ad20-4516-bd26-4ec325ff2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create an evaluation function to output all the needs metrics\n",
    "\n",
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels\n",
    "    on a classification.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds, average='micro')\n",
    "    recall = recall_score(y_true, y_preds, average='micro')\n",
    "    f1 = f1_score(y_true, y_preds, average='micro')\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2579d2cf-adf6-4ec7-922b-8dfc788b9b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step\n",
      "Acc: 90.94%\n",
      "Precision: 0.91\n",
      "Recall: 0.91\n",
      "F1 score: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91, 'precision': 0.91, 'recall': 0.91, 'f1': 0.91}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we make predictions using the test data to see how the model performs\n",
    "\n",
    "predicted = model.predict(validation_padded)\n",
    "evaluate_preds(np.argmax(validation_labels, axis=1), np.argmax(predicted, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7160162f-aa4d-41ab-ae3a-087f965f8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text):\n",
    "    seq = tokenizer.texts_to_sequences(text)\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    pred = model.predict(padded)\n",
    "  \n",
    "    predicted_label = encode.inverse_transform(pred)\n",
    "    \n",
    "    return  np.argmax(pred[0]), predicted_label[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21a632a9-579c-498d-92bc-2648a70591b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eastend set us remak plan creat us soap base bbc eastend reportedli drawn fo tv network eastend head writer toni jordan music mogul simon fuller involv project accord report hollywood report trade newspap said script commiss seri commun work class peopl chicago origin eastend pull bbc america last year prove failur rate us version british hit prove less success across atlant bbc comedi coupl remad us cast lost primetim slot nbc network due disappoint rate home eastend face rate battl recent lose rival itv soap emmer dale primetim soap us televis made recent comeback follow success abc serial desper housew seri take darkli comed look goingson group charact live suburb'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f222e120-6ef3-4ea3-aa83-86d74a905131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 'sport')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9481c175-7a95-44c4-91cb-e161d1f6d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tech'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9910a7-c3c9-47dc-ba0e-fe05ca3cee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appl laptop greatest gadget appl powerbook chosen greatest gadget time us magazin mobil pc laptop chosen one first lightweight portabl comput help defin layout futur notebook pc magazin compil alltim top list gadget includ soni walkman number three zenith remot control two gadget need move part electron warrant inclus magazin staff compil list specifi gadget also need selfcontain apparatu use subset anoth devic gener includ item potenti mobil said magazin end tri get heart realli make gadget gadget conclud oldest gadget top abacu magazin date ad put th place preelectron gadget top includ setant th posit marin chronomet nd posit kodak browni camera th posit tivo person video record newest devic make top also includ first flash mp player diamond multimedia well first success digit camera casio qv mobil phone motorola startac popular gadget moment appl ipod number list first soni transistor radio number soni third entri top cdp cd player forget crystallin hissfre blast madonna like virgin eman first cd player ask magazin karl elsen knife swiss armi knife number list gadget could said featur surprisingli low list includ origin telephon rd nintendo gameboy th pulsar quartz digit watch th list also contain plenti odditi pez sweet dispens th toy tamagotchi th bizarr ronco insid shell egg scrambler th almost everyon mobil phone mani peopl powerbook ipod find magazin convinc magnet compass still use year invent amaz obsess individu gadget rather genr eampl soni walkman first truli portabl way listen music move wherea minidisc flash mp portabl cd player etc realli improv technolog favourit true gadget probabl portabl minidisc player littl batteri power whizzi thing use froth coffe calm opinion list includ taser top gadget suspect swiss armi knife question mani item still rel unchang origin idea still use popular need laptop even pocket calcul work one list mere illustr interest cultur divid american author overwhelmingli british respons brit see mobil phone thirti sinclair whilst american focu appl tv remot tivo probabl rather obscur europ soda stream gadget chang preteen life lap top may enabl think differ cant use get busi fizzi astro war one pioneer comput game rememb spend mani hour play still work today howev tri day rubbish still great gadget time worri mobil phone soon subsum pda laptop etc marin chronomet complet revolutionis navig boat use centuri time technolog marvel soni net minidisc pave way mp player eplod onto market alway use netmd could go anywher without laptop comput gadget work tool sinclair eecut world first pocket calcul think well clockwork radio gp pocket calcul thing use real peopl pc magazin editor peopl creat list insan sure import gadget modern age mobil phone revolutionis commun said nich market laptop outsid modern age marin chronomet singl import gadget without modern transport system would evolv quickli everyon forgot brevil pie maker interest list electron gadget thousand journalist earli bless origin noteboook pc tandi size paper light three week set batteri ecel keyboard modem piti tandi make do compat appl powerbook date much gadget sure someth simpl timeless tin open swiss armi knife safeti razor blade wristwatch thing take stone hors hoov mobil phone singl devic effect way live short space time ball point pen got one use common gadget ever also mani might grate pocket calcul great improv slide rule casio pocket calcul play simpl game made tinni nois also hot gadget true gadget could carri around shown top electron toy list probabl better reflect current hightech obsess anyth els say swiss armi knife made sinclair ql machin far ahead time first home machin true multitak os shame market bad appl triumph fashion well everyth els utter rubbish ye appl laptop soni walkman classic gadget call setant marin chronomet gadget rank less import tv remot control reveal quit shock lack histor perspect former liter help chang world vastli improv navig see latter seed around couch potato cultur develop competit also put appl newton first palm pilot front runner portabl comput possibl toshiba libretto reason wish vulcan inc flipstart vapourwar otherwis would top laptop ever manag beat challeng wristwatch telephon mobil otherwis radio tv swiss armi knife far use gadget got mine year ago still wear use lot stood test time psion organis seri usabl qwerti keyboard remov storag good set app programm case design good batteri hing first think great product innov first mobil pc vote best gadget reader oferr mobil pc keep put obvious bias list site obvious mobil phone remot control reader less partisan public would tell motorola startac number one mobil phone long notebook comput gadget either gone integr commun devic psion seri first practic way carri info around would back sinclair spectrum without littl beauti would never move world earn live put mobil phone high list probabl nokia model sinclair spectrum plug tv game rubbish gave tast program live wish modern notebook even appl newest offer like pb particularli dishearten demis trackbal given way larg useless trackpad everi notebook market today use invari inaccur uncomfort cumbersom use congratul appl deserv win'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ccbb6b0-be45-4755-a026-d6c6f22312ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd47db54950>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0c7a6-61d5-4785-a7c4-d9276f444167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
